---
title: resume
seo_title: Resume
seo_desc: Mikhail Tavarez resume on his portfolio website.
---

Mikhail Tavarez
======
#### Data enthusiast with a strong background in math, science and programming. 
###### [ [My Portfolio Site](https://thatstoasty.netlify.app/) ] . [ mikhail.tavarez@outlook.com ] . [ [LinkedIn](https://www.linkedin.com/in/mikhail-tavarez-a94750b6/)] . [ ###-###-#### ] . [Austin, TX]

Experience
---------
*Accenture*
**AWS Cloud Engineer/Data Engineer** (May 2019 - Present; Austin, TX)
Client: Fortune 500 Health Services Organization
Initiative: Building Cloud First Data Warehousing platform to service numerous public facing client applications and internal dashboards.

- Development, deployment, and implementation of cloud architecture in AWS.
- Cross-functional AGILE team member delivering business value to client shareholders. Strong focus on implementation of broader AWS migration strategy.
- Development and enhancement of python scripts for data transformation, ingestion, and integration across multiple platforms and environments (Teradata, Hadoop, AWS).
- Proof of concept work to automate development efforts, reduce compute/storage costs, and vet tools/services to be integrated into AWS architecture design.
- Author python/pyspark scripts for cross platform historical data ingestion and SCD1/SCD2 change data capture (CDC) into Redshift and Aurora.
- Management and improvement of multi-team git repository and CI/CD pipeline for client AWS application.
- Automating terraform & python code unit testing using Please Build tests.
- Support application build releases into production.

*Knowledgent*
**AWS Cloud Engineer/Data Engineer** (Jan 2018 - April 2019; Warren, NJ)
Client: International Management Consulting Firm (April 2018 - April 2019)
Initiative: Developed data integration pipelines to extract and transform data from operational databases into Snowflake.

- Extracted raw data from operational databases into S3 Data Lake.
- Transformed raw operational data into Star and Snowflake data model schema.
- Performed CDC of SCD1/SCD2 dimension tables through the S3 Data Lake.
- Built reporting layer views to support Tableau dashboard visualizations.
- Implemented Snowflake's micro-batch streaming service, Snowpipe, to enable continuous data loads.

Internal Projects
Refactoring of an ML Application to AWS Sagemaker
- Developed PySpark scripts leveraging dataframes to apply data transformations to handle common data quality issues (nulls, white space, casing).
- Refactor application code to create, train, and deploy AWS XGBoost model using Sagemaker rather than open source XGBoost.
- Developed POC event-based scheduling workflow using Apache Airflow.

Investment Prediction Algorithm: Alexa Integration
- Develop and publish an Alexa skill that parses for user input through speech to text, requests inferences from a deployed XGBoost model, and returns investment predictions.
 
*DriTac Flooring Products, LLC*
**Chemical Process Engineer** (July 2016 - December 2017; Clifton, NJ)

- Increased urethane production output by 25% by analyzing equipment performance metrics.
- Automated packaging line increasing productivity by 30% and reducing 2 FTE.
- Saved $30,000/yr. by addressing excess purity, material recovery, and labor automation issues.
- Minimized variation in product intermediates by applying DOE methodology that will lead to a 100% increase in production capability for select products.
- Manage QC and Manufacturing data using SQL and Excel to determine process improvements.
- Facilitated future product demands by improving fill line efficiency.

Projects
--------
Automating ETL using AWS (November 2018 â€“ April 2019)
Developed highly available and scalable AWS framework to automate the ETL process. Driven by microservices coded in Python and deployed using SAM and CloudFormation.
- Python microservices deployed as Lambda functions, orchestrated via audit tables in PostGRES database and AWS StepFunctions.
- Publishes job metadata to ELK stack via Kinesis stream and Lambda function consumer.
- Author CloudFormation templates to provision AWS compute, storage, and IAM roles.

Skills
------
**Programming:** Python, SQL, Spark, Shell/UNIX/Bash
**AWS Services:** S3, SQS, SNS, Kinesis, RDS, Redshift, Glue, Lambda, StepFunctions, CloudFormation, IAM, CloudWatch, CloudTrail, KMS
**DevOps/Automation:** Git, Jenkins, Please Build, ConfTest, Terraform, Terragrunt, Kubernetes, Docker
**(Non) Relational DBMS:** MySQL, MS SQL Server, Snowflake, Hive/Impala, PostGRES

Certifications
------
- **AWS Certified Solutions Architect - Professional**
- **AWS Certified SysOps Administrator - Associate**
- **AWS Certified Developer - Associate**

Education
---------
**B.S. in Chemical Engineering, Rutgers University** (September 2012 - May 2016)




